{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db887e02",
   "metadata": {},
   "source": [
    "# Problem statement 10:\n",
    "1. Extract Sample document and apply following document preprocessing methods: \\\n",
    "    Tokenization, POS Tagging, stop words removal, Stemming and Lemmatization.\n",
    "2. Create representation of documents by calculating Term Frequency and Inverse Document Frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d3661f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Akash\n",
      "[nltk_data]     Kalme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92050aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Akash\n",
      "[nltk_data]     Kalme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6884071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Akash Kalme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a1fedcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Akash\n",
      "[nltk_data]     Kalme\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e885ad85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Akash\n",
      "[nltk_data]     Kalme\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d9f9ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import math\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2641d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Text Documents\n",
    "text1 = \"The major difference between Bar Chart and Histogram is the bars of the bar chart are not just next to each other. In the histogram, the bars are adjacent to each other. In statistics, bar charts and histograms are important for expressing a huge or big number of data. The similarity between bar chart and histogram is both are a pictorial representation of grouped data.\" \n",
    "text2 = \"A histogram is also a pictorial representation of data using rectangular bars, that are adjacent to each other. It is used to represent grouped frequency distribution with continuous classes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df1b5b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: \n",
      "The major difference between Bar Chart and Histogram is the bars of the bar chart are not just next to each other. In the histogram, the bars are adjacent to each other. In statistics, bar charts and histograms are important for expressing a huge or big number of data. The similarity between bar chart and histogram is both are a pictorial representation of grouped data.\n",
      "\n",
      "Text 2: \n",
      "A histogram is also a pictorial representation of data using rectangular bars, that are adjacent to each other. It is used to represent grouped frequency distribution with continuous classes.\n"
     ]
    }
   ],
   "source": [
    "# Displaying the Text Documents\n",
    "print(\"Text 1: \")\n",
    "print(text1)\n",
    "print()\n",
    "print(\"Text 2: \")\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e324da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1:\n",
      "the major difference between bar chart and histogram is the bars of the bar chart are not just next to each other in the histogram the bars are adjacent to each other in statistics bar charts and histograms are important for expressing a huge or big number of data the similarity between bar chart and histogram is both are a pictorial representation of grouped data\n",
      "\n",
      "Text 2:\n",
      "a histogram is also a pictorial representation of data using rectangular bars that are adjacent to each other it is used to represent grouped frequency distribution with continuous classes\n"
     ]
    }
   ],
   "source": [
    "# Removing punctuation from document\n",
    "text1 = text1.lower()\n",
    "text2 = text2.lower()\n",
    "text1 = text1.translate(str.maketrans('','', string.punctuation))\n",
    "text2 = text2.translate(str.maketrans('','', string.punctuation))\n",
    "\n",
    "print(\"Text 1:\")\n",
    "print(text1)\n",
    "print()\n",
    "print(\"Text 2:\")\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95c11ed",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4c3e93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Tokenization on Text 1: \n",
      "['the major difference between bar chart and histogram is the bars of the bar chart are not just next to each other in the histogram the bars are adjacent to each other in statistics bar charts and histograms are important for expressing a huge or big number of data the similarity between bar chart and histogram is both are a pictorial representation of grouped data']\n",
      "\n",
      "Sentence Tokenization on Text 2: \n",
      "['a histogram is also a pictorial representation of data using rectangular bars that are adjacent to each other it is used to represent grouped frequency distribution with continuous classes']\n"
     ]
    }
   ],
   "source": [
    "token1sent = nltk.sent_tokenize(text1)\n",
    "token2sent = nltk.sent_tokenize(text2)\n",
    "\n",
    "print(\"Sentence Tokenization on Text 1: \")\n",
    "print(token1sent)\n",
    "print()\n",
    "print(\"Sentence Tokenization on Text 2: \")\n",
    "print(token2sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41dcd429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Tokenized Text 1: \n",
      "['the', 'major', 'difference', 'between', 'bar', 'chart', 'and', 'histogram', 'is', 'the', 'bars', 'of', 'the', 'bar', 'chart', 'are', 'not', 'just', 'next', 'to', 'each', 'other', 'in', 'the', 'histogram', 'the', 'bars', 'are', 'adjacent', 'to', 'each', 'other', 'in', 'statistics', 'bar', 'charts', 'and', 'histograms', 'are', 'important', 'for', 'expressing', 'a', 'huge', 'or', 'big', 'number', 'of', 'data', 'the', 'similarity', 'between', 'bar', 'chart', 'and', 'histogram', 'is', 'both', 'are', 'a', 'pictorial', 'representation', 'of', 'grouped', 'data']\n",
      "\n",
      "Word Tokenized Text 2: \n",
      "['a', 'histogram', 'is', 'also', 'a', 'pictorial', 'representation', 'of', 'data', 'using', 'rectangular', 'bars', 'that', 'are', 'adjacent', 'to', 'each', 'other', 'it', 'is', 'used', 'to', 'represent', 'grouped', 'frequency', 'distribution', 'with', 'continuous', 'classes']\n"
     ]
    }
   ],
   "source": [
    "tokens1 = nltk.word_tokenize(text1)\n",
    "tokens2 = nltk.word_tokenize(text2)\n",
    "\n",
    "print(\"Word Tokenized Text 1: \")\n",
    "print(tokens1)\n",
    "print()\n",
    "print(\"Word Tokenized Text 2: \")\n",
    "print(tokens2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d741bf0",
   "metadata": {},
   "source": [
    "# POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c920a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tagged Tokens of Text 1: \n",
      "{('are', 'VBP'), ('and', 'CC'), ('data', 'NNS'), ('histograms', 'NNS'), ('not', 'RB'), ('statistics', 'NNS'), ('of', 'IN'), ('is', 'VBZ'), ('histogram', 'NN'), ('bar', 'NN'), ('or', 'CC'), ('expressing', 'VBG'), ('a', 'DT'), ('just', 'RB'), ('for', 'IN'), ('next', 'JJ'), ('major', 'JJ'), ('both', 'DT'), ('to', 'TO'), ('bars', 'NNS'), ('chart', 'NN'), ('huge', 'JJ'), ('adjacent', 'JJ'), ('representation', 'NN'), ('important', 'JJ'), ('between', 'IN'), ('charts', 'NNS'), ('the', 'DT'), ('similarity', 'NN'), ('pictorial', 'JJ'), ('difference', 'NN'), ('big', 'JJ'), ('number', 'NN'), ('each', 'DT'), ('in', 'IN'), ('grouped', 'VBN'), ('other', 'JJ')}\n",
      "\n",
      "POS Tagged Tokens of Text 2: \n",
      "{('are', 'VBP'), ('grouped', 'JJ'), ('data', 'NNS'), ('classes', 'NNS'), ('rectangular', 'JJ'), ('of', 'IN'), ('is', 'VBZ'), ('used', 'VBN'), ('continuous', 'JJ'), ('also', 'RB'), ('a', 'DT'), ('distribution', 'NN'), ('with', 'IN'), ('to', 'TO'), ('bars', 'NNS'), ('representation', 'NN'), ('adjacent', 'JJ'), ('it', 'PRP'), ('that', 'WDT'), ('frequency', 'NN'), ('pictorial', 'JJ'), ('using', 'VBG'), ('each', 'DT'), ('histogram', 'NN'), ('represent', 'VB'), ('other', 'JJ')}\n"
     ]
    }
   ],
   "source": [
    "pos_tagged_tokens1 = set(nltk.pos_tag(tokens1))\n",
    "pos_tagged_tokens2 = set(nltk.pos_tag(tokens2))\n",
    "\n",
    "print(\"POS Tagged Tokens of Text 1: \")\n",
    "print(pos_tagged_tokens1)\n",
    "print()\n",
    "print(\"POS Tagged Tokens of Text 2: \")\n",
    "print(pos_tagged_tokens2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950f6927",
   "metadata": {},
   "source": [
    "# Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9924b233",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'our', 'needn', 'didn', 'to', 'from', 'after', 'below', 'be', 'why', 'hers', 'where', 'am', 'ma', 'off', 'up', 'each', 'o', 'of', 'couldn', \"hadn't\", 'isn', 'yourselves', 'been', 'than', 'won', 'in', \"should've\", 'her', \"you're\", 'whom', 'against', \"shan't\", 'own', 'so', 'about', 'through', 're', 'has', 'with', 'such', 'only', 'himself', 'there', 'i', 'because', 'him', 'will', 'the', 'too', 'nor', 'those', \"you've\", 'themselves', 'did', 'doing', 'down', \"hasn't\", \"wasn't\", 'few', 'by', 'same', 'yours', \"mustn't\", 'under', 'll', 'on', 's', \"it's\", 'a', 'do', 'but', 'me', 'theirs', 'for', 'when', 'you', 'both', 'yourself', \"doesn't\", 'who', 'don', 'can', \"you'd\", 'no', 'just', 'shan', 'them', 'over', 'which', 'herself', 'y', 'while', 'then', 'ours', 'these', \"that'll\", \"couldn't\", 'being', 'm', 'she', 'once', 'wouldn', 'myself', \"won't\", \"aren't\", 'more', \"you'll\", 'that', 'itself', 'before', 't', 'his', 'mustn', 'as', 'does', 'above', 'we', 've', 'hadn', \"she's\", 'all', 'should', 'hasn', 'an', 'my', \"weren't\", 'here', 'further', 'wasn', 'was', 'were', 'haven', 'and', 'mightn', 'or', 'weren', 'into', \"isn't\", 'not', 'having', 'at', 'very', 'shouldn', 'it', 'this', \"shouldn't\", 'have', 'are', 'out', 'other', 'their', 'again', 'its', 'they', 'is', 'some', 'ain', 'had', \"mightn't\", \"haven't\", 'how', \"don't\", 'he', 'd', 'aren', 'until', 'what', 'ourselves', 'now', 'if', 'doesn', 'during', \"didn't\", 'between', 'any', 'your', \"wouldn't\", \"needn't\", 'most'}\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de18d177",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_after_stopword_removal_text_1 = []\n",
    "tokens_after_stopword_removal_text_2 = []\n",
    "\n",
    "for token in tokens1:\n",
    "    if token not in tokens_after_stopword_removal_text_1:\n",
    "        if token not in stop_words:\n",
    "            tokens_after_stopword_removal_text_1.append(token)        \n",
    "\n",
    "for token in tokens2:\n",
    "    if token not in tokens_after_stopword_removal_text_2:\n",
    "        if token not in stop_words:\n",
    "            tokens_after_stopword_removal_text_2.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01f981c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens after Stopword Removal of Text 1: \n",
      "['major', 'difference', 'bar', 'chart', 'histogram', 'bars', 'next', 'adjacent', 'statistics', 'charts', 'histograms', 'important', 'expressing', 'huge', 'big', 'number', 'data', 'similarity', 'pictorial', 'representation', 'grouped']\n",
      "\n",
      "Tokens after Stopwords Removal of Text 2: \n",
      "['histogram', 'also', 'pictorial', 'representation', 'data', 'using', 'rectangular', 'bars', 'adjacent', 'used', 'represent', 'grouped', 'frequency', 'distribution', 'continuous', 'classes']\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokens after Stopword Removal of Text 1: \")\n",
    "print(tokens_after_stopword_removal_text_1)\n",
    "print()\n",
    "print(\"Tokens after Stopwords Removal of Text 2: \")\n",
    "print(tokens_after_stopword_removal_text_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1747e173",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "023bc2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming on Text 1: \n",
      "major  :  major\n",
      "difference  :  differ\n",
      "bar  :  bar\n",
      "chart  :  chart\n",
      "histogram  :  histogram\n",
      "bars  :  bar\n",
      "next  :  next\n",
      "adjacent  :  adjac\n",
      "statistics  :  statist\n",
      "charts  :  chart\n",
      "histograms  :  histogram\n",
      "important  :  import\n",
      "expressing  :  express\n",
      "huge  :  huge\n",
      "big  :  big\n",
      "number  :  number\n",
      "data  :  data\n",
      "similarity  :  similar\n",
      "pictorial  :  pictori\n",
      "representation  :  represent\n",
      "grouped  :  group\n",
      "\n",
      "Stemming on Text 2: \n",
      "histogram  :  histogram\n",
      "also  :  also\n",
      "pictorial  :  pictori\n",
      "representation  :  represent\n",
      "data  :  data\n",
      "using  :  use\n",
      "rectangular  :  rectangular\n",
      "bars  :  bar\n",
      "adjacent  :  adjac\n",
      "used  :  use\n",
      "represent  :  repres\n",
      "grouped  :  group\n",
      "frequency  :  frequenc\n",
      "distribution  :  distribut\n",
      "continuous  :  continu\n",
      "classes  :  class\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "print(\"Stemming on Text 1: \")\n",
    "for w in tokens_after_stopword_removal_text_1:\n",
    "    print(w, \" : \", ps.stem(w))\n",
    "    \n",
    "print(\"\\nStemming on Text 2: \")\n",
    "for w in tokens_after_stopword_removal_text_2:\n",
    "    print(w, \" : \", ps.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b98da7",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "92ae2986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmetization of Text 1: \n",
      "major  :  major\n",
      "difference  :  difference\n",
      "bar  :  bar\n",
      "chart  :  chart\n",
      "histogram  :  histogram\n",
      "bars  :  bar\n",
      "next  :  next\n",
      "adjacent  :  adjacent\n",
      "statistics  :  statistic\n",
      "charts  :  chart\n",
      "histograms  :  histogram\n",
      "important  :  important\n",
      "expressing  :  expressing\n",
      "huge  :  huge\n",
      "big  :  big\n",
      "number  :  number\n",
      "data  :  data\n",
      "similarity  :  similarity\n",
      "pictorial  :  pictorial\n",
      "representation  :  representation\n",
      "grouped  :  grouped\n",
      "\n",
      "Lemmetization of Text 2: \n",
      "histogram  :  histogram\n",
      "also  :  also\n",
      "pictorial  :  pictorial\n",
      "representation  :  representation\n",
      "data  :  data\n",
      "using  :  using\n",
      "rectangular  :  rectangular\n",
      "bars  :  bar\n",
      "adjacent  :  adjacent\n",
      "used  :  used\n",
      "represent  :  represent\n",
      "grouped  :  grouped\n",
      "frequency  :  frequency\n",
      "distribution  :  distribution\n",
      "continuous  :  continuous\n",
      "classes  :  class\n"
     ]
    }
   ],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "\n",
    "print(\"Lemmetization of Text 1: \")\n",
    "for w in tokens_after_stopword_removal_text_1:\n",
    "    print(w, \" : \", lem.lemmatize(w))\n",
    "\n",
    "print(\"\\nLemmetization of Text 2: \")\n",
    "for w in tokens_after_stopword_removal_text_2:\n",
    "    print(w, \" : \", lem.lemmatize(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f0f19c",
   "metadata": {},
   "source": [
    "# Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c715c1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Frequency 1: \n",
      "{'major': 0.047619047619047616, 'difference': 0.047619047619047616, 'bar': 0.047619047619047616, 'chart': 0.047619047619047616, 'histogram': 0.047619047619047616, 'bars': 0.047619047619047616, 'next': 0.047619047619047616, 'adjacent': 0.047619047619047616, 'statistics': 0.047619047619047616, 'charts': 0.047619047619047616, 'histograms': 0.047619047619047616, 'important': 0.047619047619047616, 'expressing': 0.047619047619047616, 'huge': 0.047619047619047616, 'big': 0.047619047619047616, 'number': 0.047619047619047616, 'data': 0.047619047619047616, 'similarity': 0.047619047619047616, 'pictorial': 0.047619047619047616, 'representation': 0.047619047619047616, 'grouped': 0.047619047619047616}\n",
      "\n",
      "Term Frequency 2: \n",
      "{'histogram': 0.0625, 'also': 0.0625, 'pictorial': 0.0625, 'representation': 0.0625, 'data': 0.0625, 'using': 0.0625, 'rectangular': 0.0625, 'bars': 0.0625, 'adjacent': 0.0625, 'used': 0.0625, 'represent': 0.0625, 'grouped': 0.0625, 'frequency': 0.0625, 'distribution': 0.0625, 'continuous': 0.0625, 'classes': 0.0625}\n"
     ]
    }
   ],
   "source": [
    "term_frequency1 = {}\n",
    "term_frequency2 = {}\n",
    "\n",
    "for w in tokens_after_stopword_removal_text_1:\n",
    "    term_frequency1.update({w: (tokens_after_stopword_removal_text_1.count(w))/(len(tokens_after_stopword_removal_text_1))})\n",
    "\n",
    "for w in tokens_after_stopword_removal_text_2:\n",
    "    term_frequency2.update({w: (tokens_after_stopword_removal_text_2.count(w))/(len(tokens_after_stopword_removal_text_2))})\n",
    "\n",
    "print(\"Term Frequency 1: \")\n",
    "print(term_frequency1)\n",
    "print()\n",
    "print(\"Term Frequency 2: \")\n",
    "print(term_frequency2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3edbd354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse Term Frequency for Text 1:\n",
      "{'major': 0.6931471805599453, 'difference': 0.6931471805599453, 'bar': 0.6931471805599453, 'chart': 0.6931471805599453, 'histogram': 0.0, 'bars': 0.0, 'next': 0.6931471805599453, 'adjacent': 0.0, 'statistics': 0.6931471805599453, 'charts': 0.6931471805599453, 'histograms': 0.6931471805599453, 'important': 0.6931471805599453, 'expressing': 0.6931471805599453, 'huge': 0.6931471805599453, 'big': 0.6931471805599453, 'number': 0.6931471805599453, 'data': 0.0, 'similarity': 0.6931471805599453, 'pictorial': 0.0, 'representation': 0.0, 'grouped': 0.0}\n",
      "\n",
      "Inverse Term Frequency for Text 2:\n",
      "{'histogram': 0.0, 'also': 0.6931471805599453, 'pictorial': 0.0, 'representation': 0.0, 'data': 0.0, 'using': 0.6931471805599453, 'rectangular': 0.6931471805599453, 'bars': 0.0, 'adjacent': 0.0, 'used': 0.6931471805599453, 'represent': 0.6931471805599453, 'grouped': 0.0, 'frequency': 0.6931471805599453, 'distribution': 0.6931471805599453, 'continuous': 0.6931471805599453, 'classes': 0.6931471805599453}\n"
     ]
    }
   ],
   "source": [
    "# Inverse Term Frequency\n",
    "idf1 = {}\n",
    "idf2 = {}\n",
    "\n",
    "for w in tokens_after_stopword_removal_text_1:\n",
    "    cnt = 0\n",
    "    if tokens_after_stopword_removal_text_1.count(w) > 0:\n",
    "        cnt += 1\n",
    "    if tokens_after_stopword_removal_text_2.count(w) > 0:\n",
    "        cnt += 1\n",
    "    f = math.log(2/cnt)\n",
    "    idf1.update({w: f})\n",
    "    \n",
    "for w in tokens_after_stopword_removal_text_2:\n",
    "    cnt = 0\n",
    "    if tokens_after_stopword_removal_text_1.count(w) > 0:\n",
    "        cnt += 1\n",
    "    if tokens_after_stopword_removal_text_2.count(w) > 0:\n",
    "        cnt += 1\n",
    "    f = math.log(2/cnt)\n",
    "    idf2.update({w: f})\n",
    "    \n",
    "print(\"Inverse Term Frequency for Text 1:\")\n",
    "print(idf1)\n",
    "print()\n",
    "print(\"Inverse Term Frequency for Text 2:\")\n",
    "print(idf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f043d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
